
==Math for ML 02 ==
10. 각축으로의 편미분을 모으면 gradient vector가 됨
18. 두 일이 같이 벌어질 일은 서로 상관관계가 없어. 두 일을 곱한것과 같음 P(AnB) = P(A) * P(B)
19. **Bayes Theorem** : P(A|B) ; B가 일어난걸 알 때 A가 일어날 확률.
20. 각각의 요소가 독립적이다. 
- P(나가기 | 날씨, 습도, 바람) 는 P(날씨, 습도, 바람 | 나가기) 와 P(나가기), P(날씨, 습도) 를 통해 알 수 있음
- 후자들은 관측, 측정으로 알 수 있음.
- 독립이기에 n은 곱하기로 바꿀 수 있음.
- ㅠ자 기호는 확률을 곱한다는 뜻
21. 나간 날 9일동안 습한날 3일 -> 3/9으로 표현 (조건부 확률임). 
22. P(나가기|s, c, h, t) = a * P(나가기) * P(s/나) * P(c/나) * P(h/나) * P(t/나) 계산하면 0.0053a 나옴. 안 나갈 확률 구하면 0.0206a임. 안 나갈 확률이 높은걸 앎. 나갈 확률 + 안 나갈 확률 = 1이므로 a를 구할 수 있다. *시험나옴*


==Linear Regression 01==

6. y = ax + b. 베타B를 coefficientsl unknown constatns라 함. hat이 붙으면 추정된 값을 말함. 갖고 있는 정답값고 측정된 hat 값을 비교해서 정확도를 비교한다. 
7. **RSS** : 제곱하면 항상 0보다 크거나 같은 값이 나옴. n개의 샘플에 대해 모든 residual을 더한 것으로 기준을 잡음. y_i 햇이 B0햇 - B1햇이니 ei = yi - yi햇에 넣으면 식 3.3이 나옴. B1에 대해 편미분해서 그게 0이 되는 지점, B2도 같은 방법으로 그 지점을 찾음. y바와 x바는 각각 yi와 xi 샘플값의 평균값임.  
8. least square로 샘플의 중간을 지나는 선을 구할 수 있다. 
- 단점 :  아웃라이어라는 소수의 데이터에 의해 오류가 생길 수 있다.
9. RSS가 최소가 되는 B0와 B1을 구하고 싶을 떄 이걸 3차원으로 그려봄. B0는 7, B1은 0.05 언저리가 최적임. 
10. 두 개의 매체가 매출에 어떤 영향을 미치는지 보려면 모델링 식을 y = B0 + B1X1 + B2X2 으로 만든다 (여전히 선형이다). 이 모델링은 일차함수(선)이 아니라 면의 차원을 갖게 된다(2차원). 3개의 개별적인 simple linearer로 만들면 서로 다른 세 개의 모델에서 한가지의 예측을 도출하기 힘듦. 
11. 엡실론은 모델링이 다룰 수 없는 어떤 값. 엡실론 빠지면 y햇이 됨.  Multiple에서 RSS는 yi햇에 들어가는 내용만 바꾸면 됨. 그 후 편미분을 파라미터 수 만큼 해준다. 그냥 참고만 하면 되는 내용. newspaper의 경우 p-value를 보면 정확도가 떨어지는 데이터라 볼 수 있다. 13페이지 넘어감.


==Linear Regression 02==

2. **Linear Regression** : 하나 이상의 특성과 예측하고자 하는 목표 변수 사이의 관계 모델링. 회귀 직선과 샘플간 차이를 *offset* or *residual* 이라 함 (y^ - y). 


==Logistic Regression 01==

5. linear와 차이는 예측하고자하는 값이 연속적이냐 or descripted 인가. 해당 예시에서 linear를 사용하면 연속이 나오는데 1.5나 1.51이 나오면 애매해짐 -> 적절하지 않음. 
6. case가 두 개라면 0 또는 1이니 확률로 생각해 볼 수 있다. 이 떄 충족시켜야 할 조건은 모든 case를 다 더했을때 1이 나와야함.
8. balance가 얼마냐에 따라 이 사람이 빚을 값냐를 따짐. 'given balance일때 default = yes일 확률'. No일 확률은 1-P임. 편의상 0.5 이상이면 파산한다고 가정. 
9. 변수 하나임. (4.1)은 연속적이라 확률을 주지 못함(linear) -> 모델 파라미터는 이렇게 정리하되 함수는 (4.2)식으로 잡음 (logistic). 모든 변수 x에 대해 0과 1 사이 값이 나와야함. lim(x-> -무한)  p(x) = 0. 그리고 +무한이면 1임. (4.3)식의 왼쪽 항을 *odds*라고 함. P(x)는 yes일 확률, 1-P(x)는 no일 확률. yes와 no의 비율을 그 odds라고함. (4.4)식을 *log odds* or *logit* 임. 로짓이 X에 대해 linear한 수식이다는 뜻. 
11. 들어오는 데이터들 간 서로 영향이 없으니 독립이다. 각 샘플에 대해 yes인 샘플에 대해 yes일 확률이 높아야함. yi = 0은 no일 확률이 높아야함. 그 두 개를 곱하면 maximum이 된다. 이를 *maximum likelihood*라 함 (linear는 least 였음). 
13. 맞지 않는 변수가 들어오면 적절한 수치로 변환시킨 후 식에 넣음. 이때 모델링의 파라미터 값은 달라지나 결국 0~1 사이에 있음. 밑에 식 두 개 더해서 1이 나오는게 아니라 가로로 P(Y|Y) + P(N|Y) = 1이 나와야함. 
15. (4.8) 예시는 P(Y| balance, income, student) 형태임. 여기까지는 yes or no의 binary 형태임.
16. 아웃풋 종류(k)가 두 개 보다 클  떄임. (4.10)과 (4.11) 차이는 K번째 클래스에 대한 파라미터가 없음 (4.11)에는. (4.10) 처럼 1~K-1 까지만 알면 마지막 K는 1에서 그 전체를 뺴면 알 수 있음. (4.11)은 따라서 마지막 K번째 경우의 계산을 안 해도 되니 이득임. K번째 까지 다 일일이 하려면 (4.13)식이 됨. K클래스 대비 L클래스일 확률이 (4.12)임. 이를 통해 K와 L 중 더 확률이 높은걸 알 수 있음 (정확한 수치보다 대소관계만 따지는 법임).   
  

==Logistic Regression 02==

5. 두 식의 결과는 대소관계가 바뀌지 않으므로 같다. 로그 가능도는 작은 숫자를 곱해서 underflow가 생길일 없다 왜냐면 더하는 거니. 
6. 파이z를 y=1일 떄 확률이라 할 때, 파이z가 커지면 1에 가까울수록 에러가 적어짐을 그래프에서 볼 수 있음. y가 0이면 -log(1-파이)이면 반대로 주황색 처럼 1일 확률이 낮아지니 0일 확률이 높아짐. 즉 y가 1이든 0이든 잘 맞출수록 에러가 작아짐을 보이는 그래프임. 
7. 마지막 k번째는 나머지 다 아닌것의 확률로 구할 수 있으니 파라미터 k번째는 필요 없음.
10. 각 색깔이 각 클래스. 
11. colab 추가 : iris = datasets.load_iris(), num_sample, num_feature = iris.data.shape. stratify는 혹시 데이터가 불균형 할 때 기존의 비율을 고려하겠다는 뜻 -> 각 클래스가 골고루 잘 뽑히게 고려함.  


==Support Vector Machine==

3. (9.1)은 two dimension에서 정의되는 식.  (9.2)는 p+1 차원을 잘라주는 식.
4. 파란색 영역은 해당 식에 넣으면 0보다 큰 값 -> 분류 가능 (Hyperplane이라 함).
5. 두 클래스를 y = -1 or +1로 구분하려함. 평면방정식 (9,6)에 대해 0보다 크면 y = 1로 설정 작으면 -1로 설정해서 평면 보다 위에 위치하는지, 밑에 위치하는지로 구분 가능. 이걸 간략히 표현하면 (9.8)식임. 
7. 마진(경계면까지의 거리)이 최대화가 되게 선을 긋는다. 
8. 가까이 있는 샘플들의 거리가 좀 더 마진이 생기는 방향으로 긋는다 (2번이 maximal margin classifier가 됨). 
9. maximize 밑의 M은 margin을 뜻함. (9.10)을 만족하는 (9.9)를 구함. (9.10) 조건을 거는 이유는 모델이 제대로 학습되기 위해서임 (모델링 B들이 무한정 커지게 만드는 꼼수를 막기 위해서임). 
11. 샘플 데이터 하나 바뀌면 선을 다시 그어야 할 필요가 있음 (맥시멀을 유지하려면).
13. *support vector classifier* : 맥시멀 보단 타협한 모델임.
14. 점선간격(마진)은 넓어졌으나 식을 만족하지 않는 샘플들이 침범하게 됨. 그러나 여전히 decision(0보다 큰지 작은지)를 어기진 않음. 두번째 그래프는 '12, 1, 11, 8'은 버리고 나머지들을 classifier 함. 이러면 틀린 샘플들이 있고 마진을 침범하는 샘플들이 있으나 마진을 충분히 확보함 (틀린 경우들이 발생하나 대체로 좋다 할 수 있음). 
15. 앱실론이 n개 (샘플개수)만큼 붙음. 앱실론이 1보다 작아야 한다는게 없다는 건 M(1-e)가 음수가 되어서 샘플이 틀리는 것 까지 타협한다는 뜻. 마지막 앱실론 시그마 <= C가 틀려도 적당히 틀리도록 장치를 마련. 즉 틀린 정보들을 다 합쳤을 떄 타협하고자 하는 양 C보단 작도록 유지해야함 (C를 hyper parameter라 함). 
16. 첫 그림 : C가 커서 타협 많이 가능. 타협했다는 뜻은 마진 안쪽에 샘플이 많다는 뜻. 두 번째 그림 : C가 조금 줆 -> 마진이 줄어듦. 
18. non linear data에 대해선 feature를 가공해서 feature space를 늘림 -> 파라미터도 늘어남.
21. inner product를 통해 커널의 값을 찾음
22. xi는 새로운 샘플, xi^  기존에 갖고 있던 trained sample 차이를 비교함. 즉, 이 커널은 두 샘플들이 안 비슷하면 작은 값을 주도록 됨. 차이 크면 커널값 작아짐. locally sensitive : 가까워야 샘플에 영향을 줌 -> decision boundary가 타이트해짐. 감마가 커지면 exp가 크게 줄어듦 -> locally sensitive를 조절 할 수 있음.
23. radial kernel이 보다 타이트한 boundary를 가짐 (가까운 애들만 영향을 끼침). 마진에 가까운 애들이 support vector이고 마진 밖의 샘플들은 가까워지든 멀어지든 영향 x. 즉 support vector 간 거리가 boundary를 정함. 
24. false positive rate가 0이면 기준치가 높다는 뜻.기준치가 높으면 깐깐하게 평가한다는 건데 이때 값이 높을수록 좋음 정답률이 높다는 뜻이니. (기준치가 낮으면 true positive도 높아지고 flase positive도 높아짐 다 true로 취급해버리니). false positive의 경우 사각형 넓이가 넓을 수록 좋다 (1에 가까울 수록 좋음). 2번째 사진은 r가 파란색일 떄 넓이 제일 크니 좋은 값이라는 뜻. 
25. 디시전바운더리에서 멀리 떨어질수록 더 확실한 데이터임.

==Probabilistic Model==

14. *무조건 시험*

==Tree==

7. RSS 사용. 모든 i에 대한 모든 j의 에러 합을 구함. 이걸 줄이는 공간분리를 찾아야 함. -> 힘들기에 top down, greedy 방식으로 공간 splitting 함. (8.3)식은 1번 영역에 대한 에러 + 2번 영역에 대한 에러.  
8. 첫 번째 그림처럼 공간 분리가 불가하기에 두 번째 형태로 구현함. (*시험*  -트리 주고 공간 분리 혹은 그 반대)
9. Tree가 overfit 되지 않게 적당히 나눠야함 -> variance 설정 (<-> bias). 트리의 height가 크면 variance가 높은 모델. 작으면 bias가 큼. 
10. 트리를 일단 다 만들고 가지치기로 키를 줄인다 (Pruning). (8.4) 식 터미널 노드의 수를 |T|로 잡음. 그래서 공간 많이 자르면 터미널 노드 수 높아져서 무한정 위 식을 줄일 수 있는건 아님. cost = RSS식 + a|T| 인데 RSS는 하향 사이클로이드 곡선 처럼 생김 (|T|가 x 값, RSS를 y값으로 잡을 때). a|T|의 경우 y =  x 형태로 구현됨. 그래서 그 두 개의 접점이 되는 지점이 코스트를 낮추는 최적의 지점인듯. 
11. 오른편 그래프로 노드 수가 3개면 최적인걸 유추.
13. (8.5) error rate임. max(pmk)는 그 리전에서 가장 그것이 확률임. 그걸 1에서 빼면 k 중 불순물 비율.  불순물의 수치가 바껴야 트리구조가 바뀜. 단순 비율 차이는 변화에 sensitive하지 않음. (8.6) k하나가 아니라 모든 케이스를 고려함. 
14. node purity를 올리기위해 yes or yes로 split 하기도 함. 그렇다고 너무 많이 자르면 overfitting 발생함. 
16. trees can be very non-robust. 트리 장점 : 그래픽컬하게 보이기에 이해하고 설명하기 쉽다. 더미 변수 만들지 않고 질적 예측변수를 다루기 쉽다. 단점 : 정확도가 다른 regression보다 떨어짐. 작은 데이터 변화가 최종 예측에 큰 변화를 줄 수 있음.
19. 부모노드의 불순도 - 자식노드불순도*(자식노드/부모노드)합 으로 계산 (자식으로 불순도가 간 비율). 자식노드의 불순도가 떨어져서 순순해져야 원하는 방향임. 
21. *시험반드시나옴*  Dp는 부모노드의 불순도. 앤트로피, 지니, 미스클래피키케이션에 대해 I들을 정의. IG(Dp) = 0.5 * (1-0.5) + 0.5 * (1-0.5) = 0.5. 이고. 
IH(Dp) = -0.5log2(0.5) + 0.5log2(0.5) = 1. 
information gain은 0.125 경우, 0.5 - 40/80 * 0.375 - 40/80 * 0.375 = 0.125.  IG, IH는 B 라는 트리가 더 좋음. IG값이 더 크니까.

*코딩 문제없고, ox 문제 나오고, 증명은 나올수도 있음*

==Clustering==

4. 훈련된 데이터셋을 계속 들고다니면서 새로운 데이터에 대해 매번 연산을 해줘야함.
5. 빨간 공간안에 샘프들 사이의 거리는 전체 공간에서의 샘프들과의 거리와 그 비가 동일해야함. 
6. p가 무한대로 커지면 i개의 값을 큰 수에 영향, 
7. 밸런스를 잘 잡아주기위해선 반반이 잘 나누어져야함. variance가 더 큰 쪽으로 dimension을 자른다 (양 끝값 차이가 많이 나는게 구분하기 좋으니). 
8. a2의 배리언스가  더 크니 a2를 기준으로 삼고. 중간값 p4를 고름. 이게 트리의 루트로감. p2,3는 4보다 크니 오른쪽, p1은 작으니 왼쪽. p2와 p3은 a1을 기준으로 같은 방법으로 트리를 그림. 
13. 데이터가 추가되면 cluster 의 센터가 업데이트 될 수 있음(클러스터의 평균값을 센터로 잡으니). -> 어느 순간 특정 값에 수렴됨. 자기가 속한 클러스터에서 그 중심과 거리가 최소가 되면 좋은거임. 시작 지점을 랜덤하게 잡으니 새로 돌리면 최종값이 달라질 수 있음.
20. w(i, j)로 내가 속한 클러스터 내에서만 계산되도록 멤버십화 함. i는 샘플에대한 index, j는 클러스터에 대한 인덱스. sse가 줄어들수록 clustering이 잘 된 거임.
22. 클러스터링간 거리가 멀리 떨어질수록 적은 업데이트로도 정답에 수렴하게 됨.
23. 센트로이드로 선택되지 않은 나머지 샘프들에 대해 센트로이드와 거리를 계산하고 그 거리를 기반으로 확률 분포를 만든 후 그걸로 다음 센트로이드를 결정. 즉 3개의 센트로이드가 있고 데이터 샘플3개가 있다고 할때, 데이터 샘플이 자기 위치에서 제일 가까운 센터로이드 까지의 거리를 d라고 할 때, d1/d1+d2+d3가 d1의 센트로이드가 다음 센트로이드로 설정될 확률이 높다는거임. 즉 저 분수값잉 커지는게 확률이 높다는건 거리(d)가 멀다는 뜻이다. 그러니 먼 거리에 센터로이드를 설정해서 clustering의 역할을 수행 할 수 있음. 


----
----


==Regularization==
- 최적 부분집합 선택(Best Subset Selection)은 다중 선형 회귀 모델에서 최적의 예측 변수 집합을 선택하는 방법입니다. 이 방법은 모든 가능한 예측 변수 조합을 고려하여 각 조합의 성능을 평가하고, 가장 좋은 예측 변수 집합을 선택합니다. 일반적으로 이 방법은 다음과 같은 단계로 진행됩니다.
1. 모든 예측 변수의 가능한 모든 조합을 만듭니다. 예를 들어, 10개의 예측 변수가 있는 경우 가능한 모든 조합은 2^10 - 1개입니다. (최소한 하나의 변수가 포함된 조합을 제외하고 모두를 고려합니다)
2. 각 조합에 대해 모델을 적합시키고 모델의 성능을 평가합니다. 일반적으로 최소 제곱법(OLS)을 사용하여 모델을 적합시키고, 적합된 모델의 잔차 제곱합(RSS), 결정 계수(R-squared), AIC(Akaike Information Criterion), BIC(Bayesian Information Criterion) 등을 사용하여 모델의 성능을 평가합니다.
3. 성능 지표가 가장 좋은 모델(가장 낮은 RSS 또는 가장 높은 결정 계수 또는 가장 낮은 AIC 또는 BIC)을 선택합니다.
4. 선택된 모델의 예측 변수를 사용하여 최종 모델을 적합시키고 결과를 분석합니다.
- 최적 부분집합 선택은 가능한 모든 변수 조합을 고려하기 때문에 최적의 모델을 선택할 수 있지만, 계산 비용이 매우 높을 수 있습니다. 따라서 큰 변수 집합이나 데이터 세트에서는 사용하기 어려울 수 있습니다. 또한, 이 방법은 변수 간의 상호 작용을 고려하지 않으며, 변수 선택이 모델의 해석을 어렵게 할 수 있습니다. 이러한 한계를 극복하기 위해 더 간단하고 효율적인 변수 선택 기법인 전진 선택(Forward Selection), 후진 제거(Backward Elimination), 단계적 선택(Stepwise Selection) 등이 개발되었습니다. 이러한 방법들은 최적 부분집합 선택의 장점을 유지하면서 계산 비용을 줄이고 모델의 해석을 향상시킬 수 있습니다.

- Forward Stepwise Selection과 Backward Stepwise Selection은 다중 선형 회귀 모델에서 변수 선택을 위한 알고리즘 중 두 가지 방법입니다. 이들 방법은 모델의 예측 변수를 선택하고 모델을 구축하는 데 사용됩니다.
1. Forward Stepwise Selection: Forward Stepwise Selection은 변수를 한 번에 하나씩 추가하여 모델을 구축하는 방법입니다. 이 방법은 다음과 같은 단계로 진행됩니다.
    - 시작할 때는 어떤 예측 변수도 포함되지 않은 모델로 시작합니다.
    - 각 단계에서 모든 가능한 변수 중에서 하나를 선택하여 현재 모델에 추가합니다.
    - 추가된 각 변수에 대해 모델의 성능을 평가하고, 가장 좋은 성능을 보이는 변수를 선택합니다.
    - 선택된 변수가 추가된 모델을 기반으로 다음 단계로 진행합니다.
    - 더 이상 성능 향상이 없을 때까지 변수를 추가하는 과정을 반복합니다.
Forward Stepwise Selection은 최종 모델이 선택된 변수의 부분 집합 중에서 가장 좋은 예측 변수를 선택하기 때문에 모델의 예측력을 향상시킬 수 있습니다.
2. Backward Stepwise Selection: Backward Stepwise Selection은 모든 예측 변수를 포함한 모델로 시작하여 변수를 하나씩 제거하여 모델을 구축하는 방법입니다. 이 방법은 다음과 같은 단계로 진행됩니다.
    - 시작할 때는 모든 예측 변수가 포함된 모델로 시작합니다.
    - 각 단계에서 현재 모델에 포함된 모든 변수 중 하나를 제거하여 새로운 모델을 생성합니다.
    - 제거된 변수가 제거된 모델에 대한 성능을 평가하고, 가장 좋은 성능을 보이는 변수를 제거합니다.
    - 제거된 변수가 제거된 모델을 기반으로 다음 단계로 진행합니다.
    - 더 이상 성능 향상이 없을 때까지 변수를 제거하는 과정을 반복합니다.
Backward Stepwise Selection은 최종 모델이 선택된 변수의 부분 집합 중에서 가장 좋은 예측 변수를 선택하기 때문에 모델의 예측력을 향상시킬 수 있습니다.
이러한 두 가지 변수 선택 방법은 모델의 복잡도를 줄이고 해석 가능성을 높이는 데 도움이 됩니다. 그러나 Forward Stepwise Selection은 변수가 추가되는 순서에 따라 선택된 모델이 달라질 수 있으며, Backward Stepwise Selection은 모든 변수가 처음에 포함된 모델로 시작하기 때문에 변수의 개수가 매우 많은 경우에는 계산 비용이 높을 수 있습니다.

- Ridge Regression과 Lasso Regression은 선형 회귀 모델에서 과적합을 방지하기 위한 두 가지 주요한 정규화 기법입니다. 이 두 기법은 각각 L2 정규화와 L1 정규화를 사용하여 모델의 복잡도를 제어합니다.
1. Ridge Regression: Ridge Regression은 회귀 계수의 크기를 제한하여 모델의 복잡도를 조절하는 방법입니다. 이를 위해 회귀 계수의 제곱합을 패널티로 추가합니다. 즉, 손실 함수에 L2 norm을 추가하여 최소화해야 할 목표 함수는 다음과 같습니다.
- minimize(RSS+𝜆 ∑ (𝑗=1~𝑝) 𝛽𝑗2 )
여기서 RSS는 잔차 제곱합이고, 𝛽𝑗는 회귀 계수이며, 𝑝는 예측 변수의 수입니다. 𝜆는 정규화 강도를 조절하는 매개 변수로, 큰 값일수록 회귀 계수의 크기를 더 많이 축소시키게 됩니다.

2. Lasso Regression: Lasso Regression은 Ridge Regression과 유사하지만 L1 norm을 사용하여 패널티를 적용합니다. 이를 통해 일부 회귀 계수를 정확히 0으로 축소하여 변수 선택을 수행할 수 있습니다. 최소화해야 할 목표 함수는 다음과 같습니다.
- minimize(RSS+𝜆 ∑(𝑗=1~𝑝) ∣𝛽𝑗∣)
Lasso의 주요 특징은 변수 선택을 자동으로 수행한다는 것입니다. 즉, 일부 예측 변수의 회귀 계수가 0이 될 수 있습니다. 이는 모델의 해석을 용이하게 만들어주고, 불필요한 변수를 제거하여 모델의 복잡성을 줄일 수 있습니다.
Ridge와 Lasso의 선택은 주어진 문제와 데이터에 따라 달라집니다. Ridge는 회귀 계수를 연속적으로 축소하므로 변수 간의 상관 관계가 높을 때 유용하며, Lasso는 변수 선택이 필요할 때 유용합니다. 일반적으로 두 정규화 기법은 과적합을 방지하고 모델의 예측 성능을 향상시키는 데 도움이 됩니다.

9. forward stepwise와 best subset selection 장단점 비교. forward에서 변수 하나만 사용했을 때 가장 좋다고 판단한게 x1이라고 쳐도 실제론 x2와 x3를 선택하는게 궁극적으로 가장 좋다고 가정한다면 첫 단계에서 이미 forward stepwise는 실패하게 됨. 
10. backward는 varaiables p의 개수보다 sample n의 개수가 더 커야함 (그래야 full model이 fit됨). forward는 n < p 라도 노상관. 
13. 6.5식, 람다 크기에 따라 시그마의 영향력이 달라짐. 람다가 무한대로 가면 null 모델을 얻음. 그러면 B0만 살아남음. 즉 람다 커지면 계수들 작아짐.
15. equivariant : 입력에 따라서 변함. invariant : 입력이 변해도 모델의 계수가 바뀌지 않음. 
----
17. ax+1/10^-8y에서 y를 0y로 바꿔버리면 더 효율적임. 6.7식, 규제 텀이 제곱이 아니라 절대값으로 바뀜. 람다가 커진다는건 규제가 심해진다는 뜻.  검은선 보면 감마가 1천 정도만 되도 계수가 0이 됨. 
19. RSS는 동일함 릿지와 라소에서. 각 등고선은 rss 값이 같은 애들을 원으로 이어 놓은거다. rss를 최소화하는거만 집중하면 제일 가운데가 제일 작은 값이라 제일 좋음. 시그마w^2 <= S인데 S는 w1^2 + w2^2 <= S가 되어야 하고 이 식은 원의 방정식임. 즉 원의 영역과 겹치는 등고선 중에 rss가 가장 작은 지점이 좋은거니 저 검은 점이 제일 좋음 (rss도 최소화하고 규제인 원의 영역에도 존재함). 원이 커치면 규제가 약해진다는 거임. Lasso에서는 |w1|+|w2| <= S라서 마름모 꼴이 됨. 마찬가지로 마름모 영역에 있면서 rss 최소가 되는 지점이 w1이다. lasso의 최적의 위치는 y축이나 x축에 존재하게 됨. 이게 ridge와의 차이점임 (더 sparse한듯). **중요**

==Dimensionality Reduction==
3. project : 고차원->저차원으로 변형. 프로젝션할때 relevant info는 유지해야함. 
5. PCA : 맥시멈 varaince의 방향을 찾고자 함. 

----
18. variance가 가장 커지는 방향을 찾아가면서 차원을 줄여가는 과정. pca와 subset selection의 차이 : 1~5중 5방향을 다 가보고 어디가 좋은지 결정. subset seletion은 2,4 를 골랐다면 1,3,5는 고려 안함. 

==Ensemble Learning==
5. 테스트케이스와 훈련케이스 나눌때 데이터는 랜덤하게 분배시킴. 
6. 훈련데이터에 대해 1차,2차,고차 로 구분함.
7. 데이터가 많을수록 좋은데 테스트케이스와 훈련케이스로 나누면 더 잘 학습시킬 수 있었던 여지를 줄이는 것과 같음. 그래서 테스트에러를 overestimate 할 수도 있음. 
8. 전체 n개 중 1개만 테스트케이스, 나머지 n-1을 훈련케이스로 둠. 그걸로 validation을 따지면 맞췄냐 안맞췄냐를 알 수 있음. 이걸 n개 샘플에대해 다 수행함. 이렇게 하면 훈련시킬 데이터양의 손해가 거의 없음. 대신 n번 해야하니 오래걸림. 여러번 loocv를 해도 결과가 똑같음 (모든 케이스에 대해 다 하니 랜덤이 없음.)
9. 한번만 해도 n번 한것의 결과를 알 수 있도록 함. 
11. high leverage sample은 neighboring point가 없어 혼자 떨어져있음. 
12. 20은 outlier였는데 high leverage sample은 아님. x 값 기준 범위안에 존재하니. 근데 41은 x값 범위 벗어나니 hls임. 두번쨰 그림은 x1과 x2범위 안에 있으나. 혼자 떨어져있으니 hls 라고 할 수 있음. 
15. validation set은 케이스를 한번만 하는게 문제, loocv는 n번 하는게 문제였으니 적당히 나눠서 하는걸 k-fold cross-validation임. 이 경우 5번으로 나눔. 랜덤화는 한 번만 일어남. 한 번 섞어놓은걸 다섯 조각으로 나눠서 5번 반복함. 
17. 넘어감.
18. cross validation 기준으로 잡으면 poly를 4차로 잡고 k-fold 관점이면 10차로 잡는게 좋음. 트레이닝 에러가 10차일떄 떨어지는데 test error는 올라가니 overfitting이라는 뜻이니까. 
20. 중복을 허용해서 resampling함. 
23. 데이터가 변해도 모델이 일정하게 나오면 bias가 높고 varaince가 적은거임. 각각의 부트스트랩으로 얻은 모델을 시그마로 다 더하면 평균적인 prediction이 나옴. 
24. variance 줄이기 위해 high variance를 모아 놓기만 하면 돼서 pruning 같은게 필요 없음. 
25. 부트스트랩 샘플에 속할 확률과 속하지 않을 확률 따져봄 (부트스트랩은 중복을 허용하기에 훈련에 뽑히지 않을 샘플 있을 수 있음). 평균적으로 전체 데이터 셋중 2/3이 훈련에 포함됨. 1/3은 훈련에 포함되지 않았음. 
26. j th 샘플이 부트스트랩에 안 들어있을 확률은 (1-1/N)이 n번 반복되는 것과 같음. 이게 1/3 이다. 위에 공식에 맞게 고쳐서 치환 후 계산하면 1/e 나옴 = 1/3. 
27. 트리들의 집합. feature 선택할때 특정 feature에 의해 특징이 가려지는 현상을 방지 할 수 있는 듯. m =  p인 경우는 bagging이랑 똑같음. 여기서 특성을 몇개만 랜덤하게 선택한게 p/2나 루트p이다. 이 그림에선 루트p가 좀 더 나은걸 확인 할 수 있음. 
30. 첫그림, 모델이 모여있으면 변화 작으니 low varaince임. 근데 둘 다 bias 관점에서는 한쪽에 치우쳐진 형태이기에 둘 다 high bias임. 

==Multi Layer Perceptron== *식 유도, 증명은 안 나옴*
4. 가중치 w를 Transpose 하고 입력신호 x와 내적한게 z. 즉 w = [10, 0.1, 1, 3] 세로이고 입력신호 x = x1, x2, x3, x4이면 z는 10x1 + 0.1x2 + x3 + 3x4임.  Linearly separable 한 경우만 쓸 수 있는게 단점임. 
5. 입력 x는 입력으로 들어오는거이니 w를 이용해 학습해야함. x가 두 개면 w는 상수항 w0 포함해서 3개의 w 필요. y = 파이(w0 + w1x1 + w2x2). 델타 w0 =  w0 + 델타w0로 업데이트. 식에서 y-output은 정답 - 예측인데 정답을 맞췄으면 w가 0이 됨 (맞췄으니 w를 조정할 필요 없으니까). 
6. 밑에 예측값은 -1, 정답은 1, 에타는 1일때 xj(i)가 0.5이면 계산식이 나옴. 그래서 델타 wj = 1이 나오면 wj = wj + 1로 업데이트. 
7. 선형이면 w가 수렴되는게 보장됨. 선형이지 않으면 에러가 계속 생기므로 update가 멈추질 않음. 에타가 커지면 업데이트가 크게 일어남. 크면 수렴이 보장되지 않을 수 있음. 
8. epoch은 한 번 전체 훑는걸 말하는 듯. 
9. 업데이트할때 threshold 되기전에 w^Tz를 보고 오차 계산하는 방법 (더 효율적인 학습 가능 - 덜 오차 발생한 얘보다 큰 오차 난 애를 학습). 
12. non linear한 문제를 해결하기 위해 perceptron을 여러층으로 쌓음.  -> 모델 업데이트가 어려워짐. 
13. 1은 bias임. 파란색 에지가 w역할을 함 그래서 출발점(x)w = y(도착점)
14. Z^l = W^T x a^(l-1). 이전 레이어의 엑티베이션 a^(l-1)에 W^T(가중치)를 곱해서 그걸 파이로 넌리니얼하게 만든게 다음 층에서의 가공된 정보가 됨. 하나의 노드를 구성할떄 이전 단계의 여러개의 정보를 취합해서 형성이 됨. 층 사이 사이에 non linear한 함수 파이를 넣어 주었기 떄문에 이 층들을 하나의 층에 몽땅 쌓아 버릴 수가 없는 거임. 
15. 정답을 맞출때마다 a[i]라는 엑티베이션이 커지길 바람. 이 식이 최소화 되길 원하는게 손실함수J이니 마이너스를 붙이는 듯. 
16. backwardpass는 output의 C를 구하기 위해 뒤로 찾아찾아가서 w를 찾음 (d c / d w). 1번은 예측값과 실제값 차이를 계산함. 에러들이 지금 상태에 얼마나 기여했는지 보는 듯. 
18. 밑에식의 괄호 안이 파이(WTz) 계산한 거임. 
20. W, b를 업데이트해서 최종적으로 C에 얼마나 기여하는가를 보는거임. 
22. 첫 로우 두번째 노드가 k이고 두번째 로우 첫 번쨰 노드가 a_j^l이다. 세번째 로우 가장 마지막 노드를 q라함. 그래서 그 사이 간선은 라운드a_j^l / 라운드w_jk^l로 변화량(영향을 준 크기)를 계산할 수 있음. 편미분으로 나타낸거임. 뒤쪽 식에서 라운드 a_q^l+1 / 라운드 a_j^l은 분모가 변했을때 분자가 변하는 영향력이됨. (분모가 분자의 변화에 얼마나 영향을 줬는가)
25. Cost에 대해 l번째 레벨의 j번째 노드가 준 영향을 error로 정의함. 이때 z는 wa + b임. 
26. 시그마내용은 분자에 대해 분모가 영향을 준걸 다 더한 것. 밑에서 두번째 줄 zm^l+1은 forward propagation 방법 wa + b임. 
27. 각 레이어에 델타가 주어질때 바이어스를 업데이트 하는 방법. 라운드 c / 라운드 z 는 델타가 됨. 
28. weight 업데이트 방법. 
29. 처음에 입력 넣어서 C구하고(BP1). 이떄 activation들 다 기억해두고 이제 backward할때 델타로 bias 계산한다.

==Convolutional Neural Network==
3. CNN도 MLP 처럼 여러층 쌓아서 처리함. 입력사이즈와 무관하게 필터 사이즈 범위만 스캔함 (공간을 줄일 수 있음). 단점은 초점에 벗어난 범위면 확인할 수 없음. MLP와 달리 parameter sharing함으로 배워야 하는 학습량을 줄일 수 있음. 
4. 필터링된 y에 들어온 i라는 시그널. x는 입력. w가 필터. 입력은 순서대로 들어가니 모든 입력 신호가 마이크에 다 들어가면 필터 순과 입력 순이 뒤집혀 매칭됨. 식 안 외워도됨.
5. stride = 2 : 두 칸씩 뛰며 스캔함. convolution이니 w를 뒤집어서 wr로 필터를 계산함. y0 계산 후 두 칸 뛰고 y1 계산. 
6. input과 output 차원을 맞춰 주기 위해 패딩을 집어넣음. 패딩 넣어서 걸치는 부분부터 하나씩 뒤로 밀면서 읽어들이니. 크기가 줄어들지 않고 유지하게 하는 효과. 
8. convolution을 kernel이라함. input 3채널, output 1채널. 
9. 2d일때는 좌우 뒤집고 위아래도 뒤집음. 
11. 1/3로 영역을 줄이고 싶을때 6x6 -> 2x2가 됨. 영역을 4개로 나누고 각 영역에서 가장 큰 값만 뽑아서 구성하고 다음 단계로 넘겨줌. 위 값들은 필터링을 통해 커널을 통과한 값들이다. 즉 필터와 반응이 좋은 값들임. min-pooling은 필터와 반응이 적은게 의미있는 값이 뽑힐 거임. 
13. 여러개 아웃풋 만들고 싶으면 필터를 두 개 준비. 결국 input이 있으면 filter로 범위를 스캔하면서 output들을 뽑아냄. 
15. outputdml 1x1 은 layer 1의 5x5의 영역을 모두 보고 온 결과값임. 3x3 두개니까 18개의 파라미터만 보면 모델 학습 가능함. 만약 5x5 하나 레이어만 쓴다면 25개의 파라미터를 사용해야함. 
16. 영상임. 맨 위 값 하나가 바뀌면 뒤에 얼마나 영향을 주는지 보는거임 (앞 페이지와 반대의 메커니즘). 맨위 값 하나 바뀌면 두번째에서 3x3이 영향, 마지막에선 5x5가 영향을 바뀜. 즉 3x3이니 한 픽셀이 바뀌면 9개의 영역에서 변화가 생김 그게 두번째 라인에 보이게 됨. 
17. pooling과 stride가 들어감. 결국 앞에서 한 픽셀 변화가 뒤에선 많은 영역이 영향 받음을 표현. 예를 들어 3x3을 convolution한 걸 pooling 2x2 하면 한 픽셀이 포함하는 영역이 pooling 안 들어간 것보다 더 넓음. 한 픽셀이 포함하는 영역이 크니까 pooling 된 영역이 구성하는 영역은 줄어듦 (그림에서 0~4 x 0~4 영역임). 앞페이지는 그림상 (0~10 x 0~10) 영역(한 픽셀이 포함하는 영역이 적으니까 더 많은 파라미터로 구성해야함). 
18. 확률적으로 뉴럴연결을 끊음. 이 과정으로 이 네트워크에서 가질 수 있는 서브네트워크를 얻어내는 효과가 있음. 학습도 p만큼 줄여서 했으니 기여도도 p 줄인 만큼만 해야함. 
19. 넘어감
20. 0보다 작은 값은 버린다는게 RELU의 단점. GELU는 씀.  
23. **시험** 5x5니까 2칸씩 패딩을 했으면 원래 사이즈 나올것. 홀수일때 k-1/2로 패딩함. 그 후 2x2 풀링하니 반으로 줄음 이떄 pooling의 stride는 2인듯. 그 후 conv의 weight tensor의 dimension은 4차원임 (kh, kw, Cin, Cout). 각각 (5, 5, 32, 64). flattened은 7x7x64한 3136차원의 벡터를 만듦. perceptron의 weight dimension은 2차원 (Cin 3136, Cout 1024). 
- 28x28짜리 인풋이 들어왔고 채널은 1이다. 5x5 콘볼루션을 통해 32개의 특징을 추출함. padding은 2이다.(한쪽에 2개씩해야 원래인 5x5가 나옴). weight dimension은 kernel height x kernel width x Cin x Cout이니까 5x5x1x32의 콘불루션 layer를 가짐. 이때 bias dimension은 32임. 마지막에 나오는 각 층에 더해주는게 bias이니까. 즉 Cout만 취급. 그 후 2x2로 2칸씩 점프하니까 사이즈가 절반씩 줄어듦. 이때 padding은 없음 (28칸을 두 칸씩 뛰어넘으면 14칸 나오니까).  두번째 conv가 5x5x32x64임. flattened에 3136나오고 FC는 (cin, cout)이니까 (3136, 1024)이고 bias는 1024임. 두번째 FC는 1024x10임. 
24. 왼편 그림 overfitting아님. overfitting이면 validation이 밑으로 쳐질것. 

==RNN==
3. 순차데이터로 음성(언어)가 있음. 
4. 입력 n개 -> 출력 1개 (many to one), ai 번역은 many to many, chatgpy는 manytomany. 
5. hidden layer정보가 자기자신에게 영향을 줌. h(t) 구성하는데 h(t-1)도 영향을 줌. 즉 현재 정보 + 이전 기억 정보이용해서 정보 구성함. o(t+1)에서 백프로파게이션할때 단순히 자기 밑으로만 가는게 아니라 이전 기억레이어에도 영향을 받았으니 h(t)쪽 밑으로도 조사해야하니 복잡함.
6. weight 모델 파라미터를 3개로 구분함. Wh(현재히든스테이트) = Whh + Wxh임. 
7. bh는 히든레이어의 바이어스. 
8. whh= 1 이면 가장 안정적임. 
11. 입력 xt, 셀스테이트 ct, 히든스테이트 h(t-1)로 아웃풋 h(t)가 나옴. c(t-1)이 기억하고있는 정보, h(t-1)은 기억을 가공한 정보임. whf뜻은 인풋 h들어가서 아웃풋 f가 나온다는뜻. 행렬의 원소끼리 곱해주는 기호임(과녁기호 element wise). f값에 따라 이전 셀스테이트의 정보기억C(t-1)이 다음 셀스테이트C(t)에 얼마나 남아있을 수 있는지 결정됨. ~C는 셀스테이트이 후보정보이고 i 게이트와 결합해 내용이 결정됨. 





**Linear Regression**
- RSS는 e1^2~en^2 의 합이며 e; residual은 y-yhat을 의미함.  y는 B0 + B1X이고 yhat은 B에 hat 붙여주면 됨. RSS 줄이는 B0와 B1 찾는게 목적임. p-value 0~1사이 값 가지면 작을 수록 유의미한 관계임.
- Y = B0 + B1X1 + ... + BnXn + 앱실론에서 B는 계수(single에선 절편B0과 기울기B1), X는 독립변수임. Y는 종속 변수이며 예측하고자 하는 값임.
- Intercept는 y 높이(절편) 말하는 듯. = w0. 기울기 w1은 y/x임. y = w0 + w1x 형태. 특성 여러개면 w0x0 + w1x1 ... wmxm = y가 되고 이는 시그마wixi = w^T * x 이다.
- 상관분석(Correlation Analysis)란 상관관계(Correlation)를 이용하여 두 집단 사이의 관계를 파악하는 기법
- 상관계수 r = 𝜎𝑥y(x와 y 의 공분산) /  𝜎𝑥 𝜎y (표편x 표편y). 
- r = -1 : 음의 선형 상관관계 / 0 : 상관 관계 없음 / 1 : 양의 선형 상관관계.
- 목표변수와 상관관계가 높을 수록 관련성이 높음 (절대값 큰 것). Scatterplot과 상관관계 분석을 통해 어떤 특성을 사 용해야할지선별가능.
- 최소제곱법 : 회귀 직선으로부터 각 데이터 까지의 거리인 residual의 제곱합을 최소화 하는 방법. 실제 값을 얻기 위해서는 원래의Scale로 복원해야 함. 데이터를 나타내는 기준이다.
- 손실함수 : J(w) = 1/2 시그마(yi - yhati)^2.
- 다수의 특성을 사용할 경우 단순 선형회귀모델의 시각화 기법을 사용하기 어려움(Hyperplane의시각화가 어려움) 
- Residual Plot을 이용해 모델 성능 분석
- RSS(Residual Sum of Squares)는 회귀 분석에서 모델이 예측한 값과 실제 관측값 사이의 잔차(오차)를 제곱하여 합한 값입니다. 이것은 모델이 데이터를 설명하는 정도를 측정하는데 사용됩니다. 즉, 작은 RSS 값은 모델이 데이터를 잘 설명하고 있다는 것을 의미합니다.최소 제곱법(Least Squares Method)은 회귀 분석에서 가장 일반적으로 사용되는 방법 중 하나입니다. 이 방법은 주어진 데이터에 가장 잘 맞는 직선 또는 곡선을 찾는 데 사용됩니다. 최소 제곱법은 RSS를 최소화하는 모델 파라미터를 찾는 방법으로, 회귀 분석에서 사용되는 다양한 모델들을 평가하고 선택하는 데 사용됩니다.
- 따라서 RSS는 최소 제곱법에서 사용되는 측정 지표 중 하나이며, 최소 제곱법은 RSS를 최소화하여 데이터에 가장 잘 맞는 모델을 찾는 방법입니다.
- MSE (Mean-Squared-Error) : 회귀 분석에서 모델의 예측값과 실제 값 사이의 차이를 측정하는 지표. 1/n시그마(yi - yhati)^2. 결정계수는 R^2이다.
- MSE가 작을수록 모델의 예측 성능이 좋다고 할 수 있습니다. MSE는 회귀 모델의 손실 함수로 사용됨. 좋은 모델 일수록 오차는 랜덤하게 분포. 대부분의 경우 Train MSE <= Test MSE. Residual plot은 회귀 분석에서 모델의 성능을 시각화하는 데 사용되는 그래픽 방법인데 residual plot에 특정한 패턴이 보일 경우 MSE 모델이 해당 특징을 제대로 잡아내지 못한 것이다. 

**Logistic Regression**
- 모든 case를 다 더했을때 1이 나와야함.
- Pr(default=Yes|balance) : balance가 주어졌을 때 default가 yes일 확률을 말함. No는 1-P임.
- P(x) / 1-P(x) = e^(B0 + B1X)에서 왼편(yes와 no 비율)을 odds라고 함. odds가 0은 매우 낮은 확률, 무한은 매우 높은 확률을 뜻 함.
- linear로 평가하면 몇몇의 확률이 음수가 나오는 문제가 발생함으로 logistic으로 만들면 무조건 0과 1사이에 위치함.
- maximum likelihood : l(B0, B1) = ㅠ(i:yi=1)p(xi) * ㅠ(i:yi=0)(1-p(xi)). 여기서 B0와 B1 햇들은 이 likelihood를 maximize 하도록 선택됨. 
- p(x) = e^(B0 + B1x) / 1 + e^(B0 + B1x)이니까 테이블 보고 값 대입해서 구하면 됨.
- (https://m.blog.naver.com/pmw9440/222001218822)
- logit(P) = ln (P / (1 - P)).
- 다양한 특성 기반으로 클래스 레이블을 추정하는 것이 목표임으로 logit(P(y=1|x)) = w0x0 + w1x1 + ... + wmxm = w^Tx. 
- 어떤 샘플이 특정 클래스에 속할 확률 파이(z) = 1 / 1 + e^-z. 이때 파이는 logistic sigmoid function이고 z는 w^Tx를 말함.
- 가능도(likelihood)는 모델이 주어진 데이터를 얼마나 잘 설명하는지를 나타내는 척도입니다. 가능도를 최대화하는 것은 주어진 데이터가 주어진 모델에서 잘 나타날 확률이 높음을 의미. 

**Support Vector**
- Hyperplane : p dimension에서는 p-1이 된다.
- yi(B0 + B1xi1+ ... + Bpxip) > 0 은 yi = 1일 때 평면 보다 위에 위치, yi = -1 일때 평면 보다 아래 위치.
- maximal margin hyperplane : 가장 까까이 있는 샘플(서포트 벡터)들로 부터 가장 멀리 떨어지게 hyperplane을 긋는다. 마진은 서포트 벡터와 hyperplane 사이의 거리임. 이때의 마진이 최대화 되는 hyperplane을 선택함. 즉, hyperplane 부터 가장 가까운 서포트 벡터까지의 거리가 최대화되는 hyperplane을 찾는 것이 최대 마진 초평면을 찾는 핵심입니다.
- 기본적으로 Maxmize하는 방식으로 마진을 찾되 시그마Bj^2 = 1을 만족하도록 제한 하는 이유는 모델링 B들이 무한정 커지게 만드는 꼼수를 막기 위해서임. yi(B0 + B1xi1+ ... + Bpxip) >= M 이란 제한은 M이란 양수를 둬서 하이퍼플레인의 올바른 side에 위치하도록 보장하는 것임. 
- 샘플 데이터 하나 바뀌면 선을 다시 그어야 할 필요가 있음 (맥시멀을 유지하려면).
- support vector classifier : 맥시멀 보단 타협한 모델임. hyperplane이 실선이고 마진이 점선 영역임. 마진(실선)에 위치한 얘들이 서포트 벡터임으로 마진 사이에는 데이터가 맥시멀 모델에선 없어야하는데 여기선 있어도 됨. 아예 잘못된 side에 위치하는것도 허용.
- 여기서 제한 사항은 아까 M이 아니라 M(1-앱실론)을 주고 앱실론은 >=0 이며 그 합은 <= C(하이퍼 파라미터)이다. 이때 C를 크게 주면 마진 영역이 커지고 wrong side sample수도 많아짐
- SVM : support vector classifier에서 feature 수를 늘린 버전임.
- [서포트 벡터 머신(Support Vector Macine, SVM) (velog.io)](https://velog.io/@hyesoup/%EC%84%9C%ED%8F%AC%ED%8A%B8-%EB%B2%A1%ED%84%B0-%EB%A8%B8%EC%8B%A0Support-Vector-Macine-SVM)
- 커널(Kernel)은 데이터를 고차원의 특성 공간으로 변환하는 함수를 의미. γ는 표준편차의 역수에 해당하며, 커널의 "폭"을 조절합니다. 커널 K(xi, xi')에서 두 샘플이 안 비슷해서 차이 크면 커널값은 작아짐. radical kernel에서 locally sensitive 함(테스트 데이터의 클래스 레이블에 영향을 미치는 것은 주로 인접한 훈련 데이터에 국한된다) -> decision boundary가 타이트해짐. 감마가 커지면 exp가 크게 줄어듦 -> locally sensitive를 조절 할 수 있음. 
- 마진 밖의 샘플들은 가까워지든 멀어지든 영향 x. 즉 support vector 간 거리가 boundary를 정함. 
- 즉 r 값은 가까이 있는 것에 얼마나 더 가중치를 줄 것이냐임 감마 값이 클수록 가까운 데이터의 중요도가 올라가서 더 tight 해짐.
- 28p 공식.
- [서포트 벡터 머신(SVM, Support Vector Machine) [내가 공부한 머신러닝 #21.] : 네이버 블로그 (naver.com)](https://blog.naver.com/PostView.naver?blogId=gdpresent&logNo=221723178689)
- slack variable(s) : 허용 오차를 설정함. 16pge는 단순히 슬랙변수들의 총합을 말하는거니 C를 높게 주면 오류도 널널하게 가질 수 있으니 마진이 큰거인듯(높은 C는 낮은 제약이니 높은 용인도를 보임). 근데 30pge는 목적함수를 최소화하는게 목적이라 C가 작으면 아무런 슬랙합들의 영향력도 작을 수 밖에 없으니 wrong side 샘플들 많이 생겨도 상관없으니 마진을 넓게 유지하는 듯. 
- 1. **마진 최대화**:
    - SVM의 주된 목표는 클래스 간의 마진을 최대화하는 것입니다. 마진은 결정 경계와 가장 가까운 훈련 데이터 포인트(서포트 벡터) 사이의 거리입니다. 마진을 최대화하는 것은 일반화 오류를 최소화하는 것과 관련이 있습니다.
2. **오차 최소화 (소프트 마진 SVM)**:
    - 실제 데이터는 완벽하게 선형 분리가 가능하지 않을 수 있기 때문에, SVM은 일부 오류를 허용하는 방식으로 확장됩니다. 이를 위해 소프트 마진 SVM에서는 슬랙 변수(slack variables, ξ)를 도입합니다. 이 변수들은 각 데이터 포인트가 마진을 얼마나 위반할 수 있는지를 측정합니다.
    - 오차를 최소화하는 목적은 슬랙 변수의 합을 최소화하는 것을 포함합니다.
목적 함수의 수학적 표현
SVM의 목적 함수는 크게 두 부분으로 나눌 수 있습니다:
- **정규화 항**: 결정 경계의 간격을 최대화하는 부분입니다. 이는 하이퍼플레인의 노름(norm) 또는 가중치 벡터의 제곱의 반을 최소화하는 형태로 표현됩니다. (`1/2 * ||w||²`)
- **손실 항**: 슬랙 변수를 사용하여 데이터 포인트가 마진을 얼마나 위반하는지에 대한 총합을 최소화합니다. (`C * Σξ_i`)
따라서, SVM의 전체 목적 함수는 다음과 같이 표현됩니다:
min⁡(`1/2 * ||w||²` + `C * Σξ_i` )
여기서 C는 정규화 상수로, 오차에 대한 페널티의 강도를 조절합니다. 이 목적 함수를 최소화함으로써, SVM은 마진을 최대화하면서도 마진 위반을 최소화하는 결정 경계를 찾습니다.  여기서 C 값이 작을 때의 의미는
1. **오차 허용도 증가**: C 값이 작을 경우, 슬랙 변수 ξi​의 영향이 전체 목적 함수에서 상대적으로 작아집니다. 이는 오류를 더 많이 허용하게 되어 모델이 트레이닝 데이터에 대해 덜 민감하게 반응한다는 것을 의미합니다.
2. **일반화 향상**: C 값이 낮다는 것은 마진 오류를 비교적 덜 중요하게 여기고, 대신에 마진 자체를 넓게 유지하려고 한다는 것을 뜻합니다. 이로 인해 모델이 오버피팅(과적합)을 피하고 더 일반적인 결정 경계를 학습하는 데 도움이 될 수 있습니다.
3. **결정 경계의 단순화**: 낮은 C 값은 결정 경계가 더 단순하고 부드러워지게 만들 수 있습니다. 이는 학습 데이터의 개별적인 이상치(outliers)나 노이즈에 대해 덜 민감하게 반응하게 만듭니다.

**Probabilistic Models**
- Missing value : 다른 속성의 값으로 처리됨
- 과적합(Overfitting)은 기계 학습 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대한 일반화 성능이 떨어지는 현상
- 트리 모델에서 가지(branch)의 수를 증가시키면 훈련 데이터에 대한 정확도는 높아지지만, 새로운 데이터에 대한 일반화 성능이 저하되어 오차가 증가할 수 있습니다.
- 그래서 8p처럼 브레이크포인트를 최소한 3개의 majority examples울 갖는 걸로 구분함. 각 파티션은 majority class에 대한 최소한 3개의 인스턴스를 갖는다(마지막꺼 빼곤). 만약 인접한 파티션이 같은 majority class를 갖는다면 합병함.
- Bayes Theorem : P(A|B) = P(B|A)P(A) / P(B)
- Naive Bayes : bayes 이론에서 naively assume independence. 가우시안일 경우 식에 std dev 표준편차와 평균 mean 넣어서 구함.
- Naive Bayes는 클래스가 주어졌을 때 속성들이 서로 독립적으로 가정됩니다. 즉, 클래스가 주어졌을 때 속성들 간의 상호작용을 무시하고 각 속성이 독립적으로 발생한다고 가정합니다. 이는 속성들 사이의 상관 관계를 고려하지 않고 각각의 속성에 대해 개별적으로 확률을 계산함으로써 계산의 단순화를 가져옵니다. 그러나 만약 새로운 속성이 추가되고 이 속성이 기존 속성과 상관 관계가 있다면, Naive Bayes 모델은 이러한 상관 관계를 무시하고 각 속성을 독립적으로 처리하려고 할 것입니다. 이로 인해 모델이 제대로된 예측을 할 수 없게 되며, 학습 과정이 왜곡될 수 있습니다. 또한, 만약 새로운 속성이 기존의 온도 속성과 동일한 값을 가지고 있다면, 이 새로운 속성은 온도 속성의 가중치를 증가시킬 수 있습니다. 이는 모델이 해당 속성을 지나치게 강조하거나 왜곡하게 될 수 있습니다. 또한, 정규 분포 가정이 새로운 속성에 적용되지 않을 수 있으며, 따라서 모델의 정확성에 영향을 줄 수 있습니다. 새로운 속성이 다른 분포를 따를 경우 이를 고려하지 않으면 모델이 부정확한 예측을 할 수 있습니다. 마지막으로, 다른 분포를 적용할 수는 있지만, 이는 추가적인 모델 조정이 필요할 수 있으며, 모델의 복잡성을 증가시킬 수 있습니다. 그러나 적절한 분포를 선택하고 이를 적용함으로써 모델의 성능을 향상시킬 수 있습니다.

**Tree**
- Regression Tree : 무지성 분기
- Classification Tree와 Regression Tree의 주요 차이점은 예측값의 형태입니다. Classification Tree는 클래스 레이블을 예측하는 반면, Regression Tree는 연속형 값을 예측합니다. 또한, 각 리프 노드의 예측값이 다르다는 점에서 두 모델이 다릅니다.
- Tree Pruning : RSS 씀으로 8.3식이 작게 되는 j와 s를 구하는 거임. 
- Tree가 overfit 되지 않게 적당히 나눠야함 -> variance 설정 (<-> bias). 트리의 height가 크면 variance가 높은 모델. 작으면 bias가 큼. 
- A smaller tree with fewer splits might lead to lower variance and better interpretation.
- 트리를 일단 다 만들고 가지치기로 키를 줄인다 (Pruning). (8.4) 식 터미널 노드의 수를 |T|로 잡음. 그래서 공간 많이 자르면 터미널 노드 수 높아져서 무한정 위 식을 줄일 수 있는건 아님. cost = RSS식 + a|T| 인데 RSS는 하향 사이클로이드 곡선 처럼 생김 (|T|가 x 값, RSS를 y값으로 잡을 때). a|T|의 경우 y =  x 형태로 구현됨. 그래서 그 두 개의 접점이 되는 지점이 코스트를 낮추는 최적의 지점인듯. 
- Classification Tree : 의사결정 트리는 데이터의 특성을 기반으로 데이터를 분할하여 각 분할 영역에 속하는 데이터를 하나의 클래스로 분류합니다. 
- node purity를 올리기위해 yes or yes로 split 하기도 함. 그렇다고 너무 많이 자르면 overfitting 발생함. 
- Ginni index는 node purity 수치를 말함. 이 값이 낮으면 노드는 대부분 싱글 클래스의 샘플을 포함한다는 뜻. 
- 트리의 장단점 16pge.
- Decision Tree : Tree의 Root 부터 정보 이득(Information Gain) 이 최대화 되는 특성을 선택하여 Children 생성. Leaf node의 모든 훈련 샘플이 동일한 클래스에 속할 때 까지 분류를 반복. overfitting 방지 위한 pruning 적용.
- 정보이득 : 의사 결정 트리에서 노드를 분할할 때 사용하는 매트릭임. 
- IG(Dp, f) = I(Dp) - 시그마(j=1~m) Nj / Np * I(Dj)
- 부모노드의 불순도 빼기 저 식. 자식 노드의 불순도가 떨어져서 순순해져야 원하는 방향임. 즉 자식 노드의 불순도가 낮을 수록 정보 이득 커짐. 
- 엔트로피가 높다는 것은 데이터 세트의 클래스 레이블이 잘 섞여 있다는 의미로, 불순도가 높다고 할 수 있습니다. 즉 클래스 분포가 균등할 때 엔트로피는 최대.
- 지니 계수는 무작위로 선택한 데이터가 잘못 분류될 확률을 측정합니다. 지니 계수는 0에서 1 사이의 값으로 표현되며, 0은 완벽한 순수함을 나타내고, 1은 최대 불순도를 나타냅니다. 지니 계수는 다음 공식으로 계산됩니다
- Misclassification Error(분류 오차)는 무작위로 선택한 데이터가 잘못 분류될 확률을 직접적으로 계산합니다. 가장 빈번한 클래스를 선택할 때의 오류율을 나타냄. 노드의 클래스 확률 변화에 민감하지 않음
- 21pge 공식이용하면
- Dp - Ie : 1 - 40/80 = 0.5
- A - Dleft-Ie : 1 - 30/40 = 0.25
- A - Dright-Ie : 1 - 30/40 = 0.25
- IG - Ie : 0.5 - 40/80 * 0.25 - 40/80 * 0.25 = 0.25

- Dp - Ig : 1 - ( (40/80)^2 + (40/80)^2 ) = 0.5
- A - Dleft-Ig : 1 - ( (30/40)^2  + (10/40)^2 ) = 0.375 
- A - Dright-Ig : 1 - ( (10/40)^2  + (30/40)^2 ) = 0.375
- IG - Ig : 0.5 - 40/80 * 0.375 - 40/80 * 0.375 = 0.125

- Dp - Ih : -  ( 40/80 log2(40/80)  + 40/80log2(40/80) ) = 1
- A - Dleft - lh : - ( (3/4)log2(3/4) + (1/4)log2(1/4) ) = 0.81 ?
- A - Dright - lh : - ( (1/4)log2(1/4) + (3/4)log2(3/4) ) = 0.81 ?
- IG - lh : 1 - 1/2 * 0.81 - 1/2 * 0.81 = 0.19

**Clustering**
- 분산이 크다는 것은 해당 차원의 데이터가 넓게 퍼져 있음을 의미하며, 이는 분할을 통해 고르게 데이터를 나눌 수 있는 좋은 기회를 제공합니다.
- SSE를 cluster 내에서 최소화 하는게 좋다. 
- k means++ clustering은 초기 centroid가 서로 멀리 떨어지도록 선정해 k-means보다 일관성 있고 정확함. (일반 k means는 10번 랜덤 수행후 가장 좋은 모델 선택하는 방식).
- 즉 3개의 센트로이드가 있고 데이터 샘플3개가 있다고 할때, 데이터 샘플이 자기 위치에서 제일 가까운 센터로이드 까지의 거리를 d라고 할 때, d1/d1+d2+d3가 d1의 센트로이드가 다음 센트로이드로 설정될 확률이 높다는거임. 즉 저 분수값잉 커지는게 확률이 높다는건 거리(d)가 멀다는 뜻이다. 그러니 먼 거리에 센터로이드를 설정해서 clustering의 역할을 수행 할 수 있음. 

- Best Subset Selection은 다중 선형 회귀 모델에서 최적의 예측 변수 집합을 선택하는 방법입니다. 이 방법은 모든 가능한 예측 변수 조합을 고려하여 각 조합의 성능을 평가하고, 가장 좋은 예측 변수 집합을 선택합니다. predictors가 p개이면 2 ^p 만큼 모델 생성. RSS 가장 낮은 모델 선택. 계산 비용이 매우 높을 수 있습니다. 따라서 큰 변수 집합이나 데이터 세트에서는 사용하기 어렵다.
- Forward Stepwise Selection은 어떤 예측 변수도 포함되지 않은 모델로 시작해 변수를 하나씩 추가하여 모델을 구축하는 방법. 추가된 각 변수에 대해 모델의 성능을 평가하고, 가장 좋은 성능을 보이는 변수를 선택. 변수가 추가되는 순서에 따라 선택된 모델이 달라질 수 있음. 1+p(p+1)/2 모델 구축. 1은 최초의 널 모델이다.
- Backward Stepwise Selection은 모든 예측 변수를 포함한 모델로 시작하여 변수를 하나씩 제거하여 모델을 구축. 변수의 개수가 매우 많은 경우에는 계산 비용이 높을 수 있습니다. 1+p(p+1)/2 모델 구축. forward와 마찬가지로 최적의 모델을 도출한다고 보장할 수는 없음. 변수 간의 상호 작용을 고려하지 않으며, 변수 선택이 모델의 해석을 어렵게 할 수 있기 떄문이다.
- backward는 varaiables p의 개수보다 sample n의 개수가 더 커야함 (그래야 full model이 fit됨). forward는 n < p 라도 노상관. 
- Ridge Regression: 회귀 계수의 크기를 제한하여(감소시키며) 모델의 복잡도를 조절하는 방법입니다. 이를 위해 회귀 계수의 제곱합을 패널티로 추가합니다. 즉, 손실 함수에 L2 norm을 추가하여 최소화해야 할 목표 함수는 다음과 같습니다.
- RSS+𝜆 ∑ (𝑗=1~𝑝) (𝛽_𝑗)^2 
- RSS처럼 RSS를 minimize하면서 최적의 계수를 찾지만 감마(tunning parameter) x 시그마에 해당되는 shrinkage penalty는 B값이 0에 가까울수록 작아짐으로 패널티를 주는 효과가 있음. 따라서 감마는 이 두 항의 상대성을 고려서 값이 셋팅되어야함. 감마가 0이면 패널티가 없다. 감마가 무한이면 ridge의 계수값(RSS부분)은 0이 될 것임. 즉 RSS = 시그마(i=1~n)(y_i - B0 - 시그마(j=1~p)B_j * X_ij)^2 이므로 가중치 Bj를 지나치게 줄이면 RSS가 커짐. 지나치게 늘려도 penalty가 늘어나게 됨으로 목표함수(J)가 최적이 안될거임. 
- L2 norm : ||B|| _ 2 = 루트(시그마(j=1~p)(B_j)^2). B가 0으로 부터 얼마나 떨어졌는지를 측정. 하나의 계수만 존재하는 RSS와 달리 Ridge는 B_감마_R라는 계수가 각 감마마다 존재함. 감마가 커지면 B_감마_R의 L2놈은 항상 줄어든다. B_감마_R / L2놈 도 줄어든다. 
- 감마가 작을때 variance는 높고 bias는 낮다. 감마 커지면 varaince는 낮아지고 bias는 커진다. 그 둘의 교차점일 때가 MSE(mean squared error)가 가장 낮은 지점이다.
- 보통 bias 낮고 variance 높으면 약간의 변화에도 least squares 계수에 큰 영향을 준다. 근데 릿지는 그런 환경에서 trading off하기에 잘 작동한다.
- *감마 작으면 variance 높고 bias 낮게 되며 약간의 변화에도 큰 영향을 받는다 근데 랏쏘는 감마가 작아지면 L2놈이 커짐으로 trading off하게 동작함.*
- 릿지의 큰 단점은 final model은 모든 predictors p를 포함하게 된다는 것이다. 
- Lasso Regression : 릿지와 유사하지만 L1 norm을 사용하여 패널티를 적용합니다. 이를 통해 일부 회귀 계수를 정확히 0으로 축소하여 변수 선택을 수행할 수 있습니다. 최소화해야 할 목표 함수는 다음과 같습니다.
- RSS+𝜆 ∑(𝑗=1~𝑝) ∣𝛽_𝑗∣
-  L1 norm : ||B|| _ 1 = 시그마|B_j|.
- 랏쏘는 감마가 충분히 크면 L1 페널티는 계수가 정확히 0이 되도록 강제함 (릿지는 0에 가깝게임). 그래서 랏쏘는 variable selection이 가능함.  
- Ridge는 회귀 계수를 연속적으로 축소하므로 변수 간의 상관 관계가 높을 때 유용하며, Lasso는 변수 선택이 필요할 때 유용합니다. 일반적으로 두 정규화 기법은 과적합을 방지하고 모델의 예측 성능을 향상시키는 데 도움이 됩니다.
- Ridge는 RSS가 만드는 등고선(같은 값들은 같은 등고선)의 가운데 점인 minimize loss가 가장 적은 점에 Ridge가 만드는 minimize penalty 원의 겹치는 영역 중 가장 가까운 점이  minimize loss + penalty가 된다. w1^2 + w2^2 <= S이라 릿지는 원이 된다. 원이 커치면 규제가 약해진다는 거임.
- Lasso에서는 |w1|+|w2| <= S라서 마름모 꼴이 됨. 마찬가지로 마름모 영역에 있면서 rss 최소가 되는 지점이 w1이다. lasso의 최적의 위치는 y축이나 x축에 존재하게 됨. 이게 ridge와의 차이점임 (더 sparse(희소, 협소)한듯)

- Feature selection : 원본 특성은 유지, 백워드, 포워드, 베스트 서브셋 방식. Feature extraction : 새로운 특성 공간으로 transform하거나 고차원에서 저차원으로 project. 저장공간 개선 및 계산 효율성 늘리는 효과 있음. 
- PCA : 차원 축소를 위한 linear transformation 기술. 가장 큰 variance의 방향을 찾아 원본 보다 작거나 같은 차원으로 새로운 subspace를 project하는걸 목표로함.
- 주성분(principal components)은 데이터의 분산을 최대화하면서 서로 직교(orthogonal)하도록 구성된 새로운 축입니다. 이 축은 원래의 특성(feature)들 간의 상관 관계를 제거하여, 데이터의 구조를 더 잘 이해하고 분석할 수 있게 합니다.
- 데이터에 가장 가까운 초평면(hyperplane)을 구한 다음, 데이터를 이 초평면에 투영(projection)시킨다. - 블로그설명
- 새로운 특성 축은 서로 orthogonal해야한다는 제한사항을 고려할 때, 새로운 subspace의 principal components와 같은 orthogonal axes들은 맥시멈 variance의 방향으로 해석될 수 있다. 
- PCA는 첫 번째 주성분부터 시작하여 데이터의 분산을 가장 크게 설명하는 축을 찾습니다. 첫 번째 주성분은 원래 데이터의 분산을 최대한 포착하는 방향을 나타냅니다. 이후 주성분들은 이전 주성분들과 직교하도록 선택되며, 이 축들 또한 최대한의 분산을 설명하는 방향으로 선택됩니다. 이 과정은 모든 주성분이 서로 직교하고, 분산을 최대화하는 방향을 따르는 것을 의미합니다. 입력 데이터의 특성(feature)들이 상관관계를 갖고 있다 하더라도, PCA를 수행한 결과 생성된 주성분들은 서로 직교하게 됩니다. 이는 PCA의 특성상 주성분을 찾는 과정에서 상관관계를 제거하고, 주성분들이 서로 독립적이고 직교하게 구성되기 때문입니다.
- (x1~xd) ㅌ R^(1xd)를 갖는 벡터 x를 변환 매트릭스에 의해 변환된 W ㅌ R^(dxk)에 대해 xW = z 식을 유도할 수 있음. 이때 k차원의 특성을 갖는 subspace(k<d)로 축소시킨거라 z = (z1~zk) ㅌ R^(1xk)이다. 즉 d차원을 k차원으로 변형시킨거임 (축소). the first principal component will have the largest possible variance.
- Var(ax+b) = a2Var(x). 
- 기대값 E(X)=u, E(Y)=v 이고 u, v는 샘플의 평균일 때, 공분산 cov(X, Y) = E((X-u)(Y-v)) = E(XY) -uv. 이걸 벡터로 나타내면 (1/m-1)시그마(i=1~m)(XiYi - uv) = (1/m-1)(X^T * Y) - uv. 그냥 cov(X) = (1/m-1)(X^T * X)임. 
- PCA 구하는 단계
    - d차원 데이터를 표준화
    - 공분산 행렬 구축
    - 공분산 행렬을 eigenvector와 eigenvalue로 decompose
    - eigenvalue를 내림차순으로 정렬하여 해당 eigenvector의 순위를 지정
    - k largest eigenvalue에 해당되는 k eigenvectors를 선택
    - top-k eigenvectors로 부터 투영 행렬 W를 구축
    - 새로운 k차원 특성 subspace를 얻기 위해 투영 행렬 W을 이용해 d차원 데이터셋 X를 transform 한다.
- A positive covariance between two features indicates that the features increase or decrease together. A negative covariance indicates that the features vary in opposite directions.
- Let 𝑿 be an 𝑛 × 𝑑 matrix of 𝑛 samples(관측치) with 𝑑 standardized attributes(특성)
- xa = 시그마(j=1~d)xjaj. 데이터 x의 dx1 유닛 벡터 a에 대한 투영이다. 이때 x는 X의 row중 하나. 따라서 a에 대한 X의 모든 projected values Xa가 된다. 
- 공분산a^2 은 유도에 따라 𝒂^𝑇𝚺a가 된다. 이때 a는 variance.
- We seek 𝒂 such that (𝜎_𝒂)^2 is maximized subject to the constraint that 𝒂^𝑇𝒂 = 1 따라서
- C = 𝒂^𝑇𝚺a - 𝜆(𝒂^𝑇𝒂 - 1) 를 최대화하는게 목표.
- 만약 𝒂^𝑇𝒂가 0에 가까우면 첫항은 줄어 C는 줄어듦, 무한에 가까우면 두번째 항이 증가해서 C는 줄어듦.
- a에 대해 편미분하면, @C/@a = 2𝚺a - 2𝜆a. 이걸 0으로 만드는건 𝚺𝒂 = 𝜆𝒂즉 (𝚺 - 𝜆I)a = 0이며 𝜆는 det(𝚺-𝜆I) = 0으로 찾는다. 이때 I는 단위행렬임.
- gpt 참고
- (𝜎_𝒂)2 = 𝒂𝑇𝚺𝒂 = 𝜆. Each eigenvalue gives the variance along its axis. The first principal component 𝒂 is the eigenvector associated with the largest eigenvalue of the covariance matrix 𝚺. The second principal component orthogonal to the first one is the eigenvector corresponding to the second largest eigenvalue of 𝚺 and so on. Each principal component is represented as a linear combination of the original attributes 𝒁 = 𝑿W where 𝒁 ∈ ℝ𝑛×𝑘 ,𝑿 ∈ ℝ𝑛×𝑑 , 𝑾 ∈ ℝ𝑑×k.
- 고유값: λ1 = 7, 𝜆2 = 2. 고유벡터: v1 = (1,2)t, v2 = (-2,1)t. 이 고유값과 고유벡터를 통해 PCA를 수행할 수 있습니다. 각 고유벡터는 주성분을 나타내며, 각 고유값은 해당 주성분에 의해 설명되는 분산의 크기를 나타냅니다. 주성분들은 원래 데이터의 분산을 최대화하는 방향으로 정의되며, 서로 직교하는 속성을 가지고 있습니다.가장 큰 고유값에 대응하는 고유벡터가 첫 번째 주성분이 됩니다. 이 경우, λ1=7에 대응하는 고유벡터 v1=(1, 2)가 첫 번째 주성분입니다. 두 번째 주성분은 v2=(−2, 1)입니다. Z(변환된데이터) = X(원래데이터)W(고유벡터행렬). 여기서 고유벡터행렬은 ((1,2)t (-2,1)t)이다. 즉 ((3,2)t, (2,6)t)인 원래데이터와 행렬계산하면됨. 행렬 순서 중요하다. 
- [차원 축소 - PCA, 주성분분석 (1) (tistory.com)](https://excelsior-cjh.tistory.com/167)
- variance가 가장 커지는 방향을 찾아가면서 차원을 줄여가는 과정. pca와 subset selection의 차이 : pca는 1~5중 5방향을 다 가보고 어디가 좋은지 결정. subset seletion은 2,4 를 골랐다면 1,3,5는 고려 안함. 

- Cross Validation : Estimate the test error by holding out a subset of the training data from the fitting process. 
- validation set approach : 테스트케이스와 훈련케이스 나눌때 데이터는 랜덤하게 분배시킴. 
- 데이터는 많을수록 좋고 테스트케이스와 훈련케이스로 나누는 행위는 테스트케이스에 더 많은 데이터를 줘서 더 잘 학습 시킬 수 있었던 여지를 줄이는 것과 같음. 그래서 테스트에러를 overestimate 할 수 도 있음. 또 어떤 샘플이 훈련셋 또는 유효셋에 들어가는지에 따라 테스트에러가 크게 변화할 수 있음.
- Leave-one-out cross validation : 전체 n개 중 1개만 테스트케이스, 나머지 n-1을 훈련케이스로 둠. 그걸로 validation을 따지면 맞췄냐 안맞췄냐를 알 수 있음. 이걸 n개 샘플에대해 다 수행함. 이렇게 하면 훈련시킬 데이터양의 손해가 거의 없음(far less bias). 대신 n번 해야하니 오래걸림. 여러번 loocv를 해도 결과가 똑같음 (모든 케이스에 대해 다 하니 랜덤이 없음). 수행비용은 비싸다.
- least squares linear or polynomial regression LOOCV : 한번만 수행해도 n번 한 것의 결과를 알 수 있음. 잔차(residual)와 레버리지 값만 알면 되기 때문에 연산 비용을 크게 줄여줍니다. 따라서, 최소 제곱 회귀나 다항 회귀에서는 한 번의 계산으로 전체 LOOCV 결과를 얻을 수 있는 것입니다. 
- leverage는 독립적인 변수가 다른 관측데이터에서 얼마나 떨어져있는가를 말함. 레버리지가 크면 이웃한 포인트 없이 혼자 떨어져있다는 뜻. 
- x값 기준 범위 안에 존재하면 outlier이라도 high leverage sample은 아님. 그러나 범위 안에 있더라도 데이터 bulk에 떨어져 있으면 high leverage sample이라 판단 할 수 있음. 
- 레버리지 h는 항상 1/n~1사이이고 평균 레버리지는 (p+1)/n이다.
- k-Fold cross validation : validation set은 케이스를 한번만 하는게 문제, loocv는 n번 하는게 문제였으니 적당히 나눠서 하는걸 k-fold cross-validation임. 이 경우 5번으로 나눔. 랜덤화는 한 번만 일어남. 한 번 섞어놓은걸 다섯 조각으로 나눠서 각각 수행함. 테스트 에러는 이 다섯개의 결과인 MSE를 평균내어 구한다.  
- training eorror가 떨어지는데 test error는 올라가면 overfitting이라는 뜻. 
- Bootstrap : 중복을 허용해서 resampling함. 
- Bagging (Bootstrap aggregation) : 데이터가 변해도 모델이 일정하게 나오면 bias가 높고 varaince가 적은거임. 각각의 부트스트랩으로 얻은 모델을 시그마로 다 더하고 B(부트스트랩 갯수)로 나누면 평균적인 prediction이 나오는데 이게 Bagging이다. Bagging은 variance를 낮추는걸 목표로 함. 
- variance 줄이기 위해 high variance를 모아 놓기만 하면 돼서 pruning 같은게 필요 없음. 
- 부트스트랩 샘플에 속할 확률과 속하지 않을 확률 따져봄 (부트스트랩은 중복을 허용하기에 훈련에 뽑히지 않을 샘플 있을 수 있음 이걸 OOB라함). 평균적으로 전체 데이터 셋중 2/3이 훈련에 포함됨. 1/3은 훈련에 포함되지 않았음. j th 샘플이 부트스트랩에 안 들어있을 확률이 n번 반복되는 것과 같음.  (1 - 1/n)^n 이게 1/3 이다. e^r = lim(n->무한)(1 + r/n)^n 이니까 r에 -1 넣으면 1/e 나옴 = 1/3. 유도는 n/r = u로 잡고 1+r/n 제곱 n/r 제곱 r 을 1+1/u제곱u제곱r로 고쳐 lim u->무한으로 보내면 e^r이 나온다. [limits - $\lim_{n\rightarrow \infty}(1+\frac{r}{n})^n$ is equal to ${e^{r}}$? - Mathematics Stack Exchange](https://math.stackexchange.com/questions/115863/lim-n-rightarrow-infty1-fracrnn-is-equal-to-er)
- Random Forests : 트리들의 집합. feature 선택할때 특정 feature에 의해 특징이 가려지는 현상을 방지 할 수 있는 듯. m = p인 경우는 bagging이랑 똑같음. 여기서 특성을 몇개만 랜덤하게 선택한게 p/2나 루트p이다. 이 그림에선 루트p가 좀 더 나은걸 확인 할 수 있음. each time a split in a tree is considered, a random sample of m predictors is chosen as split candidates form the full set of p predictors. a fresh sample of m predictors is taken at each split, and typically we choose m = 루트p. Bagging과 특성 무작위성을 모두 활용하여 상관관계가 없는 의사결정 트리의 포레스트를 만드는 것. overfitting 위험성 낮추지만 시간 많이 소요.
- 첫 그림은 모델이 모여있으면 변화가 작으니 low variance임. 근데 둘 다 bias 관점에서는 한쪽에 치우쳐진 형태이기에 둘 다 high bias임. *30pge 그림*. 즉 샘플들이 잘 모여있으면 low variance, 중앙에서 많이 벗어나 있으면 high bias. 

- *MLP에서 식 유도, 증명은 안 나옴*
- Perceptron은 이진 분류 (Binary Classification)에 적용 가능. 결정함수 *파이(z) = 파이(w^Tx)*. 가중치 w를 Transpose 하고 입력신호 x와 내적한게 z. 즉 w = (10, 0.1, 1, 3)t 이고 입력신호 x = x1, x2, x3, x4이면 z는 10x1 + 0.1x2 + x3 + 3x4임.  Linearly separable 한 경우만 쓸 수 있는게 단점임. z값이 threshold(한계점) 타우보다 크거나 같으면 pos, 작으면 neg. 
- perceptron 규칙 : w를 0 또는 작은 값으로 랜덤 초기화 후 각 샘플 x에 대한 출력 y를 계산 후 w 업데이트 후 수렴까지 반복함. x가 두 개면 w는 상수항 w0 포함해서 3개의 w 필요. 학습률 기호 n을 에타라고 함. w를 이용해 학습하는거고 2차원 데이터에서 가중치 업데이트 식은(`델타w_1 = 에타(y_i - output_i)x1_i`)이고 여기서 y - output은 정답 - 예측인데 정답을 맞췄으면 w가 0이 됨 (맞췄으니 가중치 w를 조정할 필요 없으니까). 예측이 틀린경우 예를 들어 y = 1인데 예측인 y햇이 -1일 때, 식에 의해 에타(2)xj_i가 된다. xj_i가 0.5이면 델타wj = 1이 나오게 되며 wj = wj + 1로 업데이트 함.  
- Perceptron은 선형적으로 구분 가능한 데이터에 대해 사용. 선형이면 w가 수렴되는게 보장됨. 선형이지 않으면 에러가 계속 생기므로 update가 멈추질 않음. 에타가 커지면 업데이트가 크게 일어남. 크면 수렴이 보장되지 않을 수 있음. 에타가 충분히 작을 경우 수렴이 보장됨.
- epoch은 한 번 전체 훑는걸 말하는 듯. 
- Adaptive Linear Neuron : 가중치 업뎃을 위해 step function이 아닌 Linear Activation Function 사용. Class Label과 실수 출력 값을 비교하여 오차 계산. 업데이트할때 threshold 되기전에 w^Tz를 보고 오차 계산하는 방법임. 더 효율적인 학습 가능 - 덜 오차 발생한 얘보다 큰 오차 난 애를 학습시킴. 
- MLP : non linear한 문제를 해결하기 위해 perceptron을 여러층으로 쌓음. *14pge 구조*
- 이전 레이어의 엑티베이션 a^(l-1)에 W^T(가중치)를 곱해서 그걸 파이로 넌리니얼하게 만든게 다음 층에서의 가공된 정보가 됨. 하나의 노드를 구성할떄 이전 단계의 여러개의 정보를 취합해서 형성이 됨. 층 사이 사이에 non linear한 함수 파이를 넣어 주었기 떄문에 이 층들을 하나의 층에 몽땅 쌓아 버릴 수가 없는 거임. 이때 h는 hidden layer를 말함. 
- Forward Pass : z(h) = a(in)W(h), a(h) = 파이(z(h)) 가 샘플 하나에 대한 식이고 모든 샘플에 대해 Z(h) = A(in)W(h), A(h) = 파이(Z(h)), Z(out) = A(h)W(out), A(out) = 파이(Z(out)) where A(out) ㅌ R(nxt). 
- 즉 선형 조합 값 z는 이전 층의 a에 현재 층의 가중치 W를 곱해서 구하고 여기에 파이(활성화 함수 for 비선형)를 취한게 현재 층의 활성화 값인 a가 된다. 
- Backward Pass : 손실 함수에 대한 그래디언트를 계산하여 가중치와 바이어스를 업데이트하는 과정. 정답을 맞출때마다 a^(i)라는 엑티베이션이 커지길 바람. 이 식이 최소화 되길 원하는게 손실함수 J이니 마이너스를 붙이는 듯. 
- *gpt "포워드 패스 예제", "백워드 패스 예제"*
- w(l, (j, k)) 의미는 l-1 레이어의 k번째 뉴런에서 l 레이어의 j번째 뉴런으로의 가중치를 말함. 
- b(l, j) 의미는 l 레이어의 j번째 뉴런의 bias를 말함. 
- a(l, j) 의미는 l 레이어의 j번째 뉴런의 activation을 말함.
- a(l, j) = 시그(시그마(k)(*w(l, (j,k))* * *a(l-1, k))* + *b(l, j)*)
- a^l = 시그(z^l)이므로 결국
- z(l, j) = 시그마(k)(*w(l, (j,k))* * *a(l-1, k))* + *b(l, j)* 가 나옴
- The goal of backpropagation is to compute the partial derivatives 𝜕c/𝜕w and 𝜕c/𝜕b of the cost function 𝐶 with respect to any weight 𝑤 or bias 𝑏 in the network
- cost function C = 1/2 ||y-a^L||^2 = 1/2시그마(j)(*y_j* - *a(L,j)*)^2. where L 은 레이어의 수를 의미. 
- cost에 대해 델타(l, j) = @C/@z(l, j) 의미는 l 레이어의 j뉴런이 준 영향을 error로 정의함. 

- CNN도 MLP 처럼 여러층 쌓아서 처리함. 입력사이즈와 무관하게 필터 사이즈 범위만 스캔함 (공간을 줄일 수 있음). 단점은 초점에 벗어난 범위면 확인할 수 없음. MLP와 달리 parameter sharing함으로 배워야 하는 학습량을 줄일 수 있음. 
- 모든 입력 신호가 마이크에 다 들어가면 필터 순과 입력 순이 뒤집혀 매칭됨. x는 입력. w가 필터(kernel). 
- stride = 2는 두 칸 씩 뒤면 스캔, convolution이니 w를 뒤집어서 w^r로 필터를 계산함. 
- input과 output 차원을 맞춰 주기 위해 패딩을 집어넣음. 패딩 넣어서 걸치는 부분부터 하나씩 뒤로 밀면서 읽어들이니. 크기가 줄어들지 않고 유지하게 하는 효과. 
- 커널 (Kernel): 작은 크기의 행렬로, 입력 데이터의 특징을 추출하는 역할을 합니다.
- 컨볼루션 (Convolution): 커널을 사용하여 입력 데이터에서 특징 맵을 생성하는 연산입니다.
- 채널 (Channel): 입력 데이터의 깊이를 나타내며, 각 채널은 특정한 정보(예: 색상)를 포함합니다.
- 즉 채널 별로 커널을 갖게 되고 채널에 매칭 되는 인풋을 커널 사이즈 만큼, 커널 값을 계산한 것들의 모든 채널 합이 convolution이 된다. (8pge)
- pooling 영역을 줄이는 방식이고 max-pooling은 가장 큰 값을 취함 P3x3이면 stride는 (3, 3)이 되고 1/3으로 줄게 됨으로 6x6이 2x2로 변형됨. 
- input data가 멀티플 채널을 갖고 있으면 커널도 그 개수 만큼 구축해야한다. 
- Receptive Field : 25 -> 9 -> 1 일 때 3x3 을 두 번 한 거니 18개 파라미터만 스캔 하면 됨. 
- 3x3 -> 2x2로 pooling이 들어가면 한 픽셀이 포함하는 영역은 pooling을 안 한 것보다 더 넓다. 한 픽셀이 포함하는 영역이 크니까 pooling된 영역이 구성하는 영역은 줄어들 수 있는거니까. 
- Dropout : cnn 훈련 중 hidden unit의 일부를 일정 확률 p로 제거. 확률적으로 뉴럴연결을 끊음. 이 과정으로 이 네트워크에서 가질 수 있는 서브네트워크를 얻어내는 효과가 있음. 최종 모델을 이용한 추정 시 각 Hidden Unit의 평균적인 기여도를 반영하기 위해 𝑝를 출력 값에 곱하여 사용. 계산을 쉽게 하기 위해 훈련 중 Inverse Dropout 기법을 적용. 제거되지 않은 Unit의 출력을 1/𝑝 만큼 곱하여 증가시킴. 
- W_out​ = (W_in​−K+2P​ / S) +1
- W는 너비(=H 높이), K는 커널 크기, P는 패딩 크기, S는 스트라이드
- P가 2.5가 나오면 너비와 높이에 2.5씩 해줘야하는데 정수여야만 함으로 same 패딩방식을 이용함. same은 커널 크기가 홀수일때 좌우/상하에 동일한 패딩을 적용 P = floor(k-1 / 2)
- weight dimension은 kernel height x kernel width x Cin x Cout
- 마지막에 나오는 각 층에 더해주는게 bias이다. 즉 Cout만 취급.

- sequence data : 순차데이터로 음성(언어)가 있음. 상호 독립적이지 않으므로 순서가 중요함.
- many to one(text->의견), one to many(image captioning), many to many(ai번역, chatgpt)에서 many 쪽은 sequence이고 one 쪽은 일반 데이터가 됨.
- RNN : Feedforward nw와 달리 hidden layer 정보가 자기자신에게 영향을 줌. 즉 현재 정보 + 이전 기억 정보이용해서 정보를 구성함. 
- RNN 출력 계산 *7pge*
- |whh| = 1이 가장 바람직, < 1이면 vanishing gradient, > 1이면  exploding gradient. 가능한 해결책은 Gradient Clipping, Truncated Backpropagation through time, Long short term memory가 있음.
- *Long-short Term Memory* : 입력 xt, 셀스테이트 ct, 히든스테이트 h(t-1)로 아웃풋 h(t)가 나옴. c(t-1)이 기억하고있는 정보, h(t-1)은 기억을 가공한 정보임. whf뜻은 인풋 h들어가서 아웃풋 f가 나온다는뜻. 행렬의 원소끼리 곱해주는 기호임(과녁기호 element wise). f값에 따라 이전 셀스테이트의 정보기억C(t-1)이 다음 셀스테이트C(t)에 얼마나 남아있을 수 있는지 결정됨. ~C는 셀스테이트의 후보 정보이고 i 게이트와 결합해 내용이 결정됨. 

- generative : 생성형모델로서 어떤 확률 분포를 학습하는 것임
- discriminative : 입력이 들어왔을때 출력이 뭘지 학습하는 것임
- Autoencoder : 자기자신이 나올것을 학습함. 입력이 들어오면 작은 크기의 데이터로 인코딩됨. 그 후 디코딩해서 복원됨. 데이터의 컴팩트하게 압축된 것만 학습한거임(z). 이걸 이용해서 나중에 데이터를 어디에 보낼때 압축해서 보내거나 함. 즉 압축할 수 있는 능력을 학습하는게 목적임. z가 학습은 되지만 어떤 분포를 갖는지는 모르는게 단점임. 그래서 z에서 새로운 샘플을 만들진 못함.
- Denoising autoencoder : 입력에 약간의 노이즈를 첨가해서 줌. 아웃풋은 오염 제거한걸 나오도록 유도해서 오염에 강인한 모델을 만듦. ~x는 오염된 입력임.  
- 위 두 autoencoder는 출력값을 단순히 입력값과 비교해보면 정답을 알 수 있기에 레이블이 필요없는 unsupervised learning로 동작함. 
- Variational Autoencoder(VAEs) : z를 통해 어떤 분포를 갖는지 알 수 있도록 학습을 함. 이걸로 새로운 샘플을 만들어낼 수 있게됨. 
- Generative Adversarial NW (GANs) : generator와 discriminator를 싸움 붙임. 제너레이터는 데이터를 생성해내고 그걸 실제 데이터와 비교해서 학습시킴. 디스크리민네이터는 만든 데이터인지 실제 데이터인지 구분하는 행위를 함. 만약 D가 구분을 못하게 되는거면 G의 학습이 잘 된거임. 
- Image Super Resolution : 저화질 -> 고화질로 복원. 
- SRGAN : Discriminator입장에서는 전체 함수를 최대화 시키는게 목적, 즉 I^HR 인 실제 HR이미지에는 1일 주고 I^LR인 생성해내는 HR이미지에는 0을 주는데 그걸 1에서 뺀거니까 결국 맥시마이즈됨. Generator입장에서는 미니마이즈해야함. 즉 잘 만들어서 D를 속여야함. 잘 속이면 I^LR이 1에 가까운 값을 갖게 되고 그걸 1에서 뺴니까 0에 가깝게 됨. (수식은 몰라도 됨).
- srgan은 그럴듯하게 만드는 거라 정확도 측면에서는 안 쓰는게 좋을 수도 있음. 
- Transformers : RNN의 단점은 데이터를 순서대로 넣어야한다는 건데 얘는 한번에 넣어주면 됨. 전체 데이터를 한번에 보고 전체 연관성을 봄. 그걸 attention으로 표현해서 거기에 집중해서 본다. 쿼리와 키를 보고 쿼리와 키의 관계가 높으면 그 값을 가져온다.(Q, K, V). 
- Foundation model : 충분히 학습된 데이터임. 어디에 쓸 줄은 모름. 
- Diffusion Model : 노이즈로 부터 그럴듯한 모델을 만들어냄(forward). backward는 원본 데이터에 살짝 노이즈를 섞어주면 점점 노이즈를 섞어줌. 


